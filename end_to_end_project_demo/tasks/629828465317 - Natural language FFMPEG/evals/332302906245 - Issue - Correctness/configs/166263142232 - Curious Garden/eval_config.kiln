{
  "v": 1,
  "id": "166263142232",
  "created_at": "2025-07-23T13:32:22.692472",
  "created_by": "scosman",
  "name": "Curious Garden",
  "model_name": "gpt_4o",
  "model_provider": "openai",
  "config_type": "llm_as_judge",
  "properties": {
    "eval_steps": [
      "Here is the man page for ffmpeg. Does the produced command have any issues?\n\n<ffmpeg_man>\nName\n\nffmpeg - FFmpeg video converter\n\nSynopsis\n\nffmpeg [[infile options][-i infile]]... {[outfile options] outfile}...\n\nDescription\n\nAs a general rule, options are applied to the next specified file. Therefore, order is important, and you can have the same option on the command line multiple times. Each occurrence is then applied to the next input or output file.\n\n* To set the video bitrate of the output file to 64kbit/s:\n\nffmpeg -i input.avi -b 64k output.avi\n* To force the frame rate of the output file to 24 fps:\nffmpeg -i input.avi -r 24 output.avi\n* To force the frame rate of the input file (valid for raw formats only) to 1 fps and the frame rate of the output file to 24 fps:\nffmpeg -r 1 -i input.m2v -r 24 output.avi\nThe format option may be needed for raw input files.\nBy default, FFmpeg tries to convert as losslessly as possible: It uses the same audio and video parameters for the outputs as the one specified for the inputs.\n\nOptions\n\nGeneric options\n\nThese options are shared amongst the ff* tools.\n-L\nShow license.\n\n-h, -?, -help, --help\nShow help.\n-version\nShow version.\n-formats\nShow available formats.\nThe fields preceding the format names have the following meanings:\n\nD\nDecoding available\n\nE\n\nEncoding available\n\n-codecs\nShow available codecs.\nThe fields preceding the codec names have the following meanings:\n\nD\nDecoding available\n\nE\n\nEncoding available\n\nV/A/S\nVideo/audio/subtitle codec\nS\nCodec supports slices\n\nD\n\nCodec supports direct rendering\n\nT\n\nCodec can handle input truncated at random locations instead of only at frame boundaries\n\n-bsfs\nShow available bitstream filters.\n-protocols\nShow available protocols.\n-filters\nShow available libavfilter filters.\n-pix_fmts\nShow available pixel formats.\n-loglevel loglevel\nSet the logging level used by the library. loglevel is a number or a string containing one of the following values:\nquiet\npanic\nfatal\nerror\nwarning\ninfo\nverbose\ndebug\nMain options\n\n-f fmt\nForce format.\n-i filename\ninput file name\n-y\nOverwrite output files.\n\n-t duration\nRestrict the transcoded/captured video sequence to the duration specified in seconds. \"hh:mm:ss[.xxx]\" syntax is also supported.\n-fs limit_size\nSet the file size limit.\n-ss position\nSeek to given time position in seconds. \"hh:mm:ss[.xxx]\" syntax is also supported.\n-itsoffset offset\nSet the input time offset in seconds. \"[-]hh:mm:ss[.xxx]\" syntax is also supported. This option affects all the input files that follow it. The offset is added to the timestamps of the input files. Specifying a positive offset means that the corresponding streams are delayed by 'offset' seconds.\n-timestamp time\nSet the timestamp.\n-metadata key=value\nSet a metadata key/value pair.\nFor example, for setting the title in the output file:\n\nffmpeg -i in.avi -metadata title=\"my title\" out.flv\n-v number\nSet the logging verbosity level.\n-target type\nSpecify target file type (\"vcd\", \"svcd\", \"dvd\", \"dv\", \"dv50\", \"pal-vcd\", \"ntsc-svcd\", ... ). All the format options (bitrate, codecs, buffer sizes) are then set automatically. You can just type:\nffmpeg -i myfile.avi -target vcd /tmp/vcd.mpg\nNevertheless you can specify additional options as long as you know they do not conflict with the standard, as in:\nffmpeg -i myfile.avi -target vcd -bf 2 /tmp/vcd.mpg\n-dframes number\nSet the number of data frames to record.\n-scodec codec\nForce subtitle codec ('copy' to copy stream).\n-newsubtitle\nAdd a new subtitle stream to the current output stream.\n-slang code\nSet the ISO 639 language code (3 letters) of the current subtitle stream.\nVideo Options\n\n-b bitrate\nSet the video bitrate in bit/s (default = 200 kb/s).\n-vframes number\nSet the number of video frames to record.\n-r fps\nSet frame rate (Hz value, fraction or abbreviation), (default = 25).\n-s size\nSet frame size. The format is wxh (ffserver default = 160x128, ffmpeg default = same as source). The following abbreviations are recognized:\nsqcif\n128x96\nqcif\n176x144\ncif\n352x288\n\n4cif\n704x576\n16cif\n1408x1152\nqqvga\n160x120\nqvga\n320x240\nvga\n640x480\n\nsvga\n800x600\nxga\n1024x768\n\nuxga\n1600x1200\nqxga\n2048x1536\nsxga\n1280x1024\nqsxga\n2560x2048\nhsxga\n5120x4096\nwvga\n852x480\nwxga\n1366x768\nwsxga\n1600x1024\nwuxga\n1920x1200\nwoxga\n2560x1600\nwqsxga\n3200x2048\nwquxga\n3840x2400\nwhsxga\n6400x4096\nwhuxga\n7680x4800\ncga\n320x200\n\nega\n\n640x350\n\nhd480\n852x480\nhd720\n1280x720\nhd1080\n1920x1080\n-aspect aspect\nSet aspect ratio (4:3, 16:9 or 1.3333, 1.7777).\n-croptop size\nSet top crop band size (in pixels).\n-cropbottom size\nSet bottom crop band size (in pixels).\n-cropleft size\nSet left crop band size (in pixels).\n-cropright size\nSet right crop band size (in pixels).\n-padtop size\nSet top pad band size (in pixels).\n-padbottom size\nSet bottom pad band size (in pixels).\n-padleft size\nSet left pad band size (in pixels).\n-padright size\nSet right pad band size (in pixels).\n-padcolor hex_color\nSet color of padded bands. The value for padcolor is expressed as a six digit hexadecimal number where the first two digits represent red, the middle two digits green and last two digits blue (default = 000000 (black)).\n-vn\nDisable video recording.\n\n-bt tolerance\nSet video bitrate tolerance (in bits, default 4000k). Has a minimum value of: (target_bitrate/target_framerate). In 1-pass mode, bitrate tolerance specifies how far ratecontrol is willing to deviate from the target average bitrate value. This is not related to min/max bitrate. Lowering tolerance too much has an adverse effect on quality.\n-maxrate bitrate\nSet max video bitrate (in bit/s). Requires -bufsize to be set.\n-minrate bitrate\nSet min video bitrate (in bit/s). Most useful in setting up a CBR encode:\nffmpeg -i myfile.avi -b 4000k -minrate 4000k -maxrate 4000k -bufsize 1835k out.m2v\nIt is of little use elsewise.\n-bufsize size\nSet video buffer verifier buffer size (in bits).\n-vcodec codec\nForce video codec to codec. Use the \"copy\" special value to tell that the raw codec data must be copied as is.\n-sameq\nUse same video quality as source (implies VBR ).\n-pass n\nSelect the pass number (1 or 2). It is used to do two-pass video encoding. The statistics of the video are recorded in the first pass into a log file (see also the option -passlogfile), and in the second pass that log file is used to generate the video at the exact requested bitrate. On pass 1, you may just deactivate audio and set output to null, examples for Windows and Unix:\nffmpeg -i foo.mov -vcodec libxvid -pass 1 -an -f rawvideo -y NUL\nffmpeg -i foo.mov -vcodec libxvid -pass 1 -an -f rawvideo -y /dev/null\n-passlogfile prefix\nSet two-pass log file name prefix to prefix, the default file name prefix is ''ffmpeg2pass''. The complete file name will be PREFIX-N .log, where N is a number specific to the output stream.\n-newvideo\nAdd a new video stream to the current output stream.\n-vlang code\nSet the ISO 639 language code (3 letters) of the current video stream.\nAdvanced Video Options\n\n-pix_fmt format\nSet pixel format. Use 'list' as parameter to show all the supported pixel formats.\n-sws_flags flags\nSet SwScaler flags.\n-g gop_size\nSet the group of pictures size.\n-intra\nUse only intra frames.\n-vdt n\nDiscard threshold.\n-qscale q\nUse fixed video quantizer scale ( VBR ).\n-qmin q\nminimum video quantizer scale ( VBR )\n-qmax q\nmaximum video quantizer scale ( VBR )\n-qdiff q\nmaximum difference between the quantizer scales ( VBR )\n-qblur blur\nvideo quantizer scale blur ( VBR ) (range 0.0 - 1.0)\n-qcomp compression\nvideo quantizer scale compression ( VBR ) (default 0.5). Constant of ratecontrol equation. Recommended range for default rc_eq: 0.0-1.0\n-lmin lambda\nminimum video lagrange factor ( VBR )\n-lmax lambda\nmax video lagrange factor ( VBR )\n-mblmin lambda\nminimum macroblock quantizer scale ( VBR )\n-mblmax lambda\nmaximum macroblock quantizer scale ( VBR )\nThese four options (lmin, lmax, mblmin, mblmax) use 'lambda' units, but you may use the QP2LAMBDA constant to easily convert from 'q' units:\n\nffmpeg -i src.ext -lmax 21*QP2LAMBDA dst.ext\n-rc_init_cplx complexity\ninitial complexity for single pass encoding\n-b_qfactor factor\nqp factor between P- and B-frames\n-i_qfactor factor\nqp factor between P- and I-frames\n-b_qoffset offset\nqp offset between P- and B-frames\n-i_qoffset offset\nqp offset between P- and I-frames\n-rc_eq equation\nSet rate control equation (default = \"tex^qComp\").\n-rc_override override\nrate control override for specific intervals\n-me_method method\nSet motion estimation method to method. Available methods are (from lowest to best quality):\nzero\nTry just the (0, 0) vector.\nphods\nlog\nx1\n\nhex\n\numh\n\nepzs\n(default method)\nfull\nexhaustive search (slow and marginally better than epzs)\n-dct_algo algo\nSet DCT algorithm to algo. Available values are:\n0\nFF_DCT_AUTO (default)\n\n1\n\nFF_DCT_FASTINT\n\n2\n\nFF_DCT_INT\n\n3\n\nFF_DCT_MMX\n\n4\n\nFF_DCT_MLIB\n\n5\n\nFF_DCT_ALTIVEC\n\n-idct_algo algo\nSet IDCT algorithm to algo. Available values are:\n0\nFF_IDCT_AUTO (default)\n\n1\n\nFF_IDCT_INT\n\n2\n\nFF_IDCT_SIMPLE\n\n3\n\nFF_IDCT_SIMPLEMMX\n\n4\n\nFF_IDCT_LIBMPEG2MMX\n\n5\n\nFF_IDCT_PS2\n\n6\n\nFF_IDCT_MLIB\n\n7\n\nFF_IDCT_ARM\n\n8\n\nFF_IDCT_ALTIVEC\n\n9\n\nFF_IDCT_SH4\n\n10\n\nFF_IDCT_SIMPLEARM\n\n-er n\nSet error resilience to n.\n1\nFF_ER_CAREFUL (default)\n\n2\n\nFF_ER_COMPLIANT\n\n3\n\nFF_ER_AGGRESSIVE\n\n4\n\nFF_ER_VERY_AGGRESSIVE\n\n-ec bit_mask\nSet error concealment to bit_mask. bit_mask is a bit mask of the following values:\n1\nFF_EC_GUESS_MVS (default = enabled)\n\n2\n\nFF_EC_DEBLOCK (default = enabled)\n\n-bf frames\nUse 'frames' B-frames (supported for MPEG-1 , MPEG-2 and MPEG-4 ).\n-mbd mode\nmacroblock decision\n0\nFF_MB_DECISION_SIMPLE: Use mb_cmp (cannot change it yet in FFmpeg).\n\n1\n\nFF_MB_DECISION_BITS: Choose the one which needs the fewest bits.\n\n2\n\nFF_MB_DECISION_RD: rate distortion\n\n-4mv\nUse four motion vector by macroblock ( MPEG-4 only).\n-part\nUse data partitioning ( MPEG-4 only).\n-bug param\nWork around encoder bugs that are not auto-detected.\n-strict strictness\nHow strictly to follow the standards.\n-aic\nEnable Advanced intra coding (h263+).\n-umv\nEnable Unlimited Motion Vector (h263+)\n-deinterlace\nDeinterlace pictures.\n-ilme\nForce interlacing support in encoder ( MPEG-2 and MPEG-4 only). Use this option if your input file is interlaced and you want to keep the interlaced format for minimum losses. The alternative is to deinterlace the input stream with -deinterlace, but deinterlacing introduces losses.\n-psnr\nCalculate PSNR of compressed frames.\n-vstats\nDump video coding statistics to vstats_HHMMSS.log.\n-vstats_file file\nDump video coding statistics to file.\n-top n\ntop=1/bottom=0/auto=-1 field first\n-dc precision\nIntra_dc_precision.\n-vtag fourcc/tag\nForce video tag/fourcc.\n-qphist\nShow QP histogram.\n-vbsf bitstream_filter\nBitstream filters available are \"dump_extra\", \"remove_extra\", \"noise\", \"h264_mp4toannexb\", \"imxdump\", \"mjpegadump\".\nffmpeg -i h264.mp4 -vcodec copy -vbsf h264_mp4toannexb -an out.h264\nAudio Options\n\n-aframes number\nSet the number of audio frames to record.\n-ar freq\nSet the audio sampling frequency (default = 44100 Hz).\n-ab bitrate\nSet the audio bitrate in bit/s (default = 64k).\n-aq q\nSet the audio quality (codec-specific, VBR ).\n-ac channels\nSet the number of audio channels (default = 1).\n-an\nDisable audio recording.\n\n-acodec codec\nForce audio codec to codec. Use the \"copy\" special value to specify that the raw codec data must be copied as is.\n-newaudio\nAdd a new audio track to the output file. If you want to specify parameters, do so before \"-newaudio\" (\"-acodec\", \"-ab\", etc..).\nMapping will be done automatically, if the number of output streams is equal to the number of input streams, else it will pick the first one that matches. You can override the mapping using \"-map\" as usual.\n\nExample:\n\nffmpeg -i file.mpg -vcodec copy -acodec ac3 -ab 384k test.mpg -acodec mp2 -ab 192k -newaudio\n-alang code\nSet the ISO 639 language code (3 letters) of the current audio stream.\nAdvanced Audio options:\n\n-atag fourcc/tag\nForce audio tag/fourcc.\n-absf bitstream_filter\nBitstream filters available are \"dump_extra\", \"remove_extra\", \"noise\", \"mp3comp\", \"mp3decomp\".\nSubtitle options:\n\n-scodec codec\nForce subtitle codec ('copy' to copy stream).\n-newsubtitle\nAdd a new subtitle stream to the current output stream.\n-slang code\nSet the ISO 639 language code (3 letters) of the current subtitle stream.\n-sn\nDisable subtitle recording.\n\n-sbsf bitstream_filter\nBitstream filters available are \"mov2textsub\", \"text2movsub\".\nffmpeg -i file.mov -an -vn -sbsf mov2textsub -scodec copy -f rawvideo sub.txt\nAudio/Video grab options\n\n-vc channel\nSet video grab channel ( DV1394 only).\n-tvstd standard\nSet television standard ( NTSC , PAL ( SECAM )).\n-isync\nSynchronize read on input.\nAdvanced options\n\n-map input_stream_id[:sync_stream_id]\nSet stream mapping from input streams to output streams. Just enumerate the input streams in the order you want them in the output. sync_stream_id if specified sets the input stream to sync against.\n-map_meta_data outfile:infile\nSet meta data information of outfile from infile.\n-debug\nPrint specific debug info.\n-benchmark\nShow benchmarking information at the end of an encode. Shows CPU time used and maximum memory consumption. Maximum memory consumption is not supported on all systems, it will usually display as 0 if not supported.\n-dump\nDump each input packet.\n-hex\nWhen dumping packets, also dump the payload.\n-bitexact\nOnly use bit exact algorithms (for codec testing).\n-ps size\nSet RTP payload size in bytes.\n-re\nRead input at native frame rate. Mainly used to simulate a grab device.\n\n-loop_input\nLoop over the input stream. Currently it works only for image streams. This option is used for automatic FFserver testing.\n-loop_output number_of_times\nRepeatedly loop output for formats that support looping such as animated GIF (0 will loop the output infinitely).\n-threads count\nThread count.\n-vsync parameter\nVideo sync method. 0 Each frame is passed with its timestamp from the demuxer to the muxer 1 Frames will be duplicated and dropped to achieve exactly the requested constant framerate. 2 Frames are passed through with their timestamp or dropped so as to prevent 2 frames from having the same timestamp -1 Chooses between 1 and 2 depending on muxer capabilities. This is the default method.\nWith -map you can select from which stream the timestamps should be taken. You can leave either video or audio unchanged and sync the remaining stream(s) to the unchanged one.\n\n-async samples_per_second\nAudio sync method. \"Stretches/squeezes\" the audio stream to match the timestamps, the parameter is the maximum samples per second by which the audio is changed. -async 1 is a special case where only the start of the audio stream is corrected without any later correction.\n-copyts\nCopy timestamps from input to output.\n-shortest\nFinish encoding when the shortest input stream ends.\n-dts_delta_threshold\nTimestamp discontinuity delta threshold.\n-muxdelay seconds\nSet the maximum demux-decode delay.\n-muxpreload seconds\nSet the initial demux-decode delay.\nPreset files\n\nA preset file contains a sequence of option=value pairs, one for each line, specifying a sequence of options which would be awkward to specify on the command line. Lines starting with the hash ('#') character are ignored and are used to provide comments. Check the ffpresets directory in the FFmpeg source tree for examples.\nPreset files are specified with the \"vpre\", \"apre\", \"spre\", and \"fpre\" options. The \"fpre\" option takes the filename of the preset instead of a preset name as input and can be used for any kind of codec. For the \"vpre\", \"apre\", and \"spre\" options, the options specified in a preset file are applied to the currently selected codec of the same type as the preset option.\n\nThe argument passed to the \"vpre\", \"apre\", and \"spre\" preset options identifies the preset file to use according to the following rules:\n\nFirst ffmpeg searches for a file named arg.ffpreset in the directories $FFMPEG_DATADIR (if set), and $HOME/.ffmpeg, and in the datadir defined at configuration time (usually PREFIX/share/ffmpeg) in that order. For example, if the argument is \"libx264-max\", it will search for the file libx264-max.ffpreset.\n\nIf no such file is found, then ffmpeg will search for a file named codec_name-arg.ffpreset in the above-mentioned directories, where codec_name is the name of the codec to which the preset file options will be applied. For example, if you select the video codec with \"-vcodec libx264\" and use \"-vpre max\", then it will search for the file libx264-max.ffpreset.\n\n@anchor{FFmpeg formula evaluator}\n\nFFmpeg formula evaluator\n\nWhen evaluating a rate control string, FFmpeg uses an internal formula evaluator.\nThe following binary operators are available: \"+\", \"-\", \"*\", \"/\", \"^\".\n\nThe following unary operators are available: \"+\", \"-\", \"(...)\".\n\nThe following statements are available: \"ld\", \"st\", \"while\".\n\nThe following functions are available:\n\nsinh(x)\ncosh(x)\ntanh(x)\nsin(x)\ncos(x)\ntan(x)\natan(x)\nasin(x)\nacos(x)\nexp(x)\nlog(x)\nabs(x)\nsquish(x)\ngauss(x)\nmod(x, y)\nmax(x, y)\nmin(x, y)\neq(x, y)\ngte(x, y)\ngt(x, y)\nlte(x, y)\nlt(x, y)\nbits2qp(bits)\nqp2bits(qp)\nThe following constants are available:\nPI\nE\n\niTex\npTex\ntex\nmv\n\nfCode\niCount\nmcVar\nvar\nisI\n\nisP\n\nisB\n\navgQP\nqComp\navgIITex\navgPITex\navgPPTex\navgBPTex\navgTex\nExamples\n\nVideo and Audio grabbing\n\nFFmpeg can grab video and audio from devices given that you specify the input format and device.\nffmpeg -f oss -i /dev/dsp -f video4linux2 -i /dev/video0 /tmp/out.mpg\nNote that you must activate the right video source and channel before launching FFmpeg with any TV viewer such as xawtv (<http://linux.bytesex.org/xawtv/>) by Gerd Knorr. You also have to set the audio recording levels correctly with a standard mixer.\nX11 grabbing\n\nFFmpeg can grab the X11 display.\nffmpeg -f x11grab -s cif -i :0.0 /tmp/out.mpg\n0.0 is display.screen number of your X11 server, same as the DISPLAY environment variable.\nffmpeg -f x11grab -s cif -i :0.0+10,20 /tmp/out.mpg\n0.0 is display.screen number of your X11 server, same as the DISPLAY environment variable. 10 is the x-offset and 20 the y-offset for the grabbing.\nVideo and Audio file format conversion\n\n* FFmpeg can use any supported file format and protocol as input:\nExamples:\n\n* You can use YUV files as input:\n\nffmpeg -i /tmp/test%d.Y /tmp/out.mpg\nIt will use the files:\n/tmp/test0.Y, /tmp/test0.U, /tmp/test0.V,\n/tmp/test1.Y, /tmp/test1.U, /tmp/test1.V, etc...\nThe Y files use twice the resolution of the U and V files. They are raw files, without header. They can be generated by all decent video decoders. You must specify the size of the image with the -s option if FFmpeg cannot guess it.\n* You can input from a raw YUV420P file:\n\nffmpeg -i /tmp/test.yuv /tmp/out.avi\ntest.yuv is a file containing raw YUV planar data. Each frame is composed of the Y plane followed by the U and V planes at half vertical and horizontal resolution.\n* You can output to a raw YUV420P file:\n\nffmpeg -i mydivx.avi hugefile.yuv\n* You can set several input files and output files:\nffmpeg -i /tmp/a.wav -s 640x480 -i /tmp/a.yuv /tmp/a.mpg\nConverts the audio file a.wav and the raw YUV video file a.yuv to MPEG file a.mpg.\n* You can also do audio and video conversions at the same time:\n\nffmpeg -i /tmp/a.wav -ar 22050 /tmp/a.mp2\nConverts a.wav to MPEG audio at 22050 Hz sample rate.\n* You can encode to several formats at the same time and define a mapping from input stream to output streams:\n\nffmpeg -i /tmp/a.wav -ab 64k /tmp/a.mp2 -ab 128k /tmp/b.mp2 -map 0:0 -map 0:0\nConverts a.wav to a.mp2 at 64 kbits and to b.mp2 at 128 kbits. '-map file:index' specifies which input stream is used for each output stream, in the order of the definition of output streams.\n* You can transcode decrypted VOBs:\n\nffmpeg -i snatch_1.vob -f avi -vcodec mpeg4 -b 800k -g 300 -bf 2 -acodec libmp3lame -ab 128k snatch.avi\nThis is a typical DVD ripping example; the input is a VOB file, the output an AVI file with MPEG-4 video and MP3 audio. Note that in this command we use B-frames so the MPEG-4 stream is DivX5 compatible, and GOP size is 300 which means one intra frame every 10 seconds for 29.97fps input video. Furthermore, the audio stream is MP3-encoded so you need to enable LAME support by passing \"--enable-libmp3lame\" to configure. The mapping is particularly useful for DVD transcoding to get the desired audio language.\nNOTE: To see the supported input formats, use \"ffmpeg -formats\".\n\n* You can extract images from a video, or create a video from many images:\n\nFor extracting images from a video:\n\nffmpeg -i foo.avi -r 1 -s WxH -f image2 foo-%03d.jpeg\nThis will extract one video frame per second from the video and will output them in files named foo-001.jpeg, foo-002.jpeg, etc. Images will be rescaled to fit the new WxH values.\nIf you want to extract just a limited number of frames, you can use the above command in combination with the -vframes or -t option, or in combination with -ss to start extracting from a certain point in time.\n\nFor creating a video from many images:\n\nffmpeg -f image2 -i foo-%03d.jpeg -r 12 -s WxH foo.avi\nThe syntax \"foo-%03d.jpeg\" specifies to use a decimal number composed of three digits padded with zeroes to express the sequence number. It is the same syntax supported by the C printf function, but only formats accepting a normal integer are suitable.\n* You can put many streams of the same type in the output:\n\nffmpeg -i test1.avi -i test2.avi -vcodec copy -acodec copy -vcodec copy -acodec copy test12.avi -newvideo -newaudio\nIn addition to the first video and audio streams, the resulting output file test12.avi will contain the second video and the second audio stream found in the input streams list.\nThe \"-newvideo\", \"-newaudio\" and \"-newsubtitle\" options have to be specified immediately after the name of the output file to which you want to add them.\n</ffmpeg_man>",
      "Think though the following criteria step by step\n\nThe eval should pass if:\n- produces a valid and runable ffmpeg command (to your knowledge), with no invalid flags or parameters\n- the produced ffmpeg command follows user request, as much as a valid command can follow the user request\n\nTo not be too hard on the eval. Only fail commands that make a mistake, not just those that could be improved in some way.\n\nSome additional considerations:\n- The eval should always fail if the produced ffmpeg is not valid or won't run (eg - it uses invalid parameters, etc).\n- If the user specifically asks for something invalid (a non-existent parameter), the task may have to deviate from user direction to produce a valid command - that's okay. If it explains the issue and offers a reasonable alternative, the eval should still pass.\n- When a user asks for something that may be a bad decision (such as a very unpopular and inefficient codec, or presets that is uncommon and not recommended), but isn't invalid, the final command should reflect their wishes. The response can warn them that they may be making a mistake, but the final command should follow any valid user directive."
    ],
    "task_description": "You are an expert in writing commands for the `ffmpeg` command line tool. You’ll be provided a message from a user asking for a transformation of a media file, and you’ll respond with an appropriate ffmpeg command. \n\nRespond with a brief explanation of the technique/parameters, followed by the needed command in triple backtick quotes. Explain any assumptions you had to make.\n\nHere’s an example user input, and high quality output:\n\n<user_message>\nI want to convert the video input.avi into a 720p mp4 file which can be streamed in a browser.\n</user_message>\n\n<output>\nTo convert input.avi into a 720p MP4 suitable for browser streaming, use H.264 video and AAC audio codecs (widely supported in browsers), set the resolution to 720 high, and enable fragmented MP4 for streaming (-movflags +faststart).\n\n- vf scale=-2:720 resizes the video to 720 height while maintaining the aspect ratio of the original (assuming you want to maintain aspect ratio). -2 ensures the height is divisible by 2 (libx264 requirement for yuv420p).\n- c:v libx264 uses H.264 video encoding.\n- preset slow focuses on compression efficiency over encoding speed. Use `fast` to invert that priority.\n- crf 23 sets quality (lower is better; 23 is a good default).\n- c:a aac -b:a 128k encodes audio using AAC at 128 kbps.\n- pix_fmt yuv420p ensures compatibility with older browsers/devices.\n- movflags +faststart places metadata at the beginning for fast streaming.\n\n```bash\nffmpeg -i input.avi -vf scale=-2:720 -c:v libx264 -preset fast -crf 23 -c:a aac -b:a 128k -pix_fmt yuv420p -movflags +faststart output.mp4\n```\n</output>"
  },
  "model_type": "eval_config"
}